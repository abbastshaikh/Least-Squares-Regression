package main;
import regressor.*;
import util.MatrixOperations;
import util.UnivariateGaussian;

/*
 * Least Squares Analysis Demonstration for:
 * 
 * Linear Regression
 * Polynomial Regression
 * Exponential Regression
 * Logarithmic Regression
 * Multiple Linear Regression 
 * 
 */

public class Main {

	public static void main (String [] args) {
		
		/*
		Linear Regression
		*/ 

		// First, we will generate data to be modeled (1000 observations from x = 0 to x = 10)
		// Assume our data is generated by y = 1.234 x + 5.678 with added Gaussian noise (sigma = 1)
		double [] xCorLinear = new double [1000];
		double [] yCorLinear = new double [1000];	

		double xMin = 0;
		double xMax = 10;

		UnivariateGaussian noise = new UnivariateGaussian(0, 1);

		for (int i = 0; i < 1000; i ++){

			double xCor = xMin + Math.random() * (xMax - xMin);
			double yCor = 1.234 * xCor + 5.678 + noise.sample();

			xCorLinear[i] = xCor;
			yCorLinear[i] = yCor;

		}

		// Now, we can train and evaluate our linear regression model
		System.out.println("Linear Regression");
		LinearRegressor linearRegression = new LinearRegressor(MatrixOperations.transpose1D(xCorLinear), yCorLinear);
		System.out.println("R-Squared: " + linearRegression.evaluate(MatrixOperations.transpose1D(xCorLinear), yCorLinear));
		linearRegression.graph();
		System.out.println();

		/*
		Polynomial Regression
		*/ 

		// First, we will generate data to be modeled (1000 observations from x = -10 to x = 10)
		// Assume our data is generated by y = 0.12x^3 + 0.34x^2 + 0.56x + 0.78 with added Gaussian noise (sigma = 20)
		double [] xCorPolynomial = new double [1000];
		double [] yCorPolynomial = new double [1000];
		
		xMin = -10;
		xMax = 10;

		noise = new UnivariateGaussian(0, 20);

		for (int i = 0; i < 1000; i ++){

			double xCor = xMin + Math.random() * (xMax - xMin);
			double yCor = 0.12 * Math.pow(xCor, 3) + 0.34 * Math.pow(xCor, 2)  + 0.56 * xCor + 0.78 + noise.sample();

			xCorPolynomial[i] = xCor;
			yCorPolynomial[i] = yCor;

		}

		// Now, we can train and evaluate our polynomial regression model
		System.out.println("Polynomial Regression");
		PolynomialRegressor polynomialRegression = new PolynomialRegressor(MatrixOperations.transpose1D(xCorPolynomial), yCorPolynomial, 3);
		System.out.println("R-Squared: " + polynomialRegression.evaluate(MatrixOperations.transpose1D(xCorPolynomial), yCorPolynomial));
		polynomialRegression.graph();
		System.out.println();
		

		/*
		Exponential Regression
		*/ 

		// First, we will generate data to be modeled (1000 observations from x = 0 to x = 10)
		// Assume our data is generated by y = 0.5678 * 1.234 ^ x with added Gaussian noise (sigma = 0.5)
		double [] xCorExponential = new double [1000];
		double [] yCorExponential = new double [1000];
		
		xMin = 0;
		xMax = 10;

		noise = new UnivariateGaussian(0, 0.5);

		for (int i = 0; i < 1000; i ++){

			double xCor = xMin + Math.random() * (xMax - xMin);
			double yCor = Math.max(0.0001, 0.5678 * Math.pow(1.234, xCor) + noise.sample());

			xCorExponential[i] = xCor;
			yCorExponential[i] = yCor;

		}

		// Now, we can train and evaluate our exponential regression model
		System.out.println("Exponential Regression");
		ExponentialRegressor exponentialRegression = new ExponentialRegressor(MatrixOperations.transpose1D(xCorExponential), yCorExponential, Math.E);
		System.out.println("R-Squared: " + exponentialRegression.evaluate(MatrixOperations.transpose1D(xCorExponential), yCorExponential));
		exponentialRegression.graph();
		System.out.println();

		/*
		Logarithmic Regression
		*/ 

		// First, we will generate data to be modeled (1000 observations from x = 0 to x = 10)
		// Assume our data is generated by y = 12.34 + 56.78 ln(x) with added Gaussian noise (sigma = 5)
		double [] xCorLogarithmic = new double [1000];
		double [] yCorLogarithmic = new double [1000];
		
		xMin = 0;
		xMax = 10;

		noise = new UnivariateGaussian(0, 5);

		for (int i = 0; i < 1000; i ++){

			double xCor = xMin + Math.random() * (xMax - xMin);
			double yCor = 1.234 + 5.678 * Math.log(xCor) + noise.sample();

			xCorLogarithmic[i] = xCor;
			yCorLogarithmic[i] = yCor;

		}

		// Now, we can train and evaluate our logarithmic regression model
		System.out.println("Logarithmic Regression");
		LogarithmicRegressor logarithmicRegression = new LogarithmicRegressor(MatrixOperations.transpose1D(xCorLogarithmic), yCorLogarithmic);
		System.out.println("R-Squared: " + logarithmicRegression.evaluate(MatrixOperations.transpose1D(xCorLogarithmic), yCorLogarithmic));
		logarithmicRegression.graph();
		System.out.println();

		/*
		Multiple Linear Regression
		*/ 

		// First, we will generate data to be modeled (1000 observations with all x_i distributed between 0 and 10)
		// Assume our data is generated by y = 0.1 + 2.3x_1 + 4.5x_2 + 6.7x_3 + 8.9x_4 with added Gaussian noise (sigma = 5)
		double [][] xCorMultivariate = new double [1000][4];
		double [] yCorMultivariate = new double [1000];
		
		xMin = 0;
		xMax = 10;

		noise = new UnivariateGaussian(0, 5);

		for (int i = 0; i < 1000; i ++){

			double [] xCor = new double [4];

			for (int j = 0; j < 4; j ++){
				xCor[j] = xMin + Math.random() * (xMax - xMin);
			}

			double yCor = 0.1 + 2.3 * xCor[0] + 4.5 * xCor[1] + 6.7 * xCor[2] + 8.9 * xCor[3] + noise.sample();

			xCorMultivariate[i] = xCor;
			yCorMultivariate[i] = yCor;

		}

		// Now, we can train and evaluate our multiple linear regression model
		System.out.println("Multiple Linear Regression");
		MultipleLinearRegressor multipleLinearRegression = new MultipleLinearRegressor(xCorMultivariate, yCorMultivariate);
		System.out.println("R-Squared: " + multipleLinearRegression.evaluate(xCorMultivariate, yCorMultivariate));
		System.out.println();
		
	}

}
